from typing import List, Dict, Any, Optional
from loguru import logger
from app.core.config import settings
from app.services.legislation_search import unified_search

try:
    from langchain_openai import ChatOpenAI
    from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
    LANGCHAIN_AVAILABLE = True
except ImportError:
    LANGCHAIN_AVAILABLE = False
    logger.warning(
        "LangChain n√£o est√° dispon√≠vel. Funcionalidades de chat desabilitadas.")


class ChatService:
    """Servi√ßo para processamento de chat com IA"""

    def __init__(self):
        self.llm = None
        self._initialize_llm()

    def _initialize_llm(self):
        """Inicializar modelo de linguagem"""
        if not LANGCHAIN_AVAILABLE:
            logger.warning("LangChain n√£o dispon√≠vel. Chat desabilitado.")
            return

        try:
            # Prioridade: OpenAI > Groq
            if settings.OPENAI_API_KEY and settings.OPENAI_API_KEY.strip():
                self.llm = ChatOpenAI(
                    model="gpt-4o-mini",  # Modelo mais barato e eficiente da OpenAI
                    temperature=0.7,
                    api_key=settings.OPENAI_API_KEY
                )
                logger.info("Modelo OpenAI GPT-4o-mini inicializado")
            elif settings.GROQ_API_KEY and settings.GROQ_API_KEY.strip():
                # Groq usa API compat√≠vel com OpenAI
                # Modelos dispon√≠veis: llama-3.1-8b-instant, mixtral-8x7b-32768, gemma-7b-it
                self.llm = ChatOpenAI(
                    # Modelo gratuito do Groq (atualizado)
                    model="llama-3.1-8b-instant",
                    temperature=0.7,
                    api_key=settings.GROQ_API_KEY,
                    base_url="https://api.groq.com/openai/v1"
                )
                logger.info("Modelo Groq (Llama 3.1 8B Instant) inicializado")
            else:
                logger.warning(
                    "Nenhuma chave de API configurada. Chat desabilitado.")
        except Exception as e:
            logger.error(f"Erro ao inicializar modelo de linguagem: {str(e)}")
            self.llm = None

    async def chat(
        self,
        message: str,
        conversation_history: Optional[List[Dict[str, str]]] = None
    ) -> Dict[str, Any]:
        """
        Processar mensagem do usu√°rio e retornar resposta

        Args:
            message: Mensagem do usu√°rio
            conversation_history: Hist√≥rico de conversa anterior

        Returns:
            Dict com 'message', 'sources' e 'suggestions'
        """
        if not self.llm:
            return {
                "message": "Desculpe, o servi√ßo de chat n√£o est√° dispon√≠vel no momento. Por favor, configure uma chave de API (OPENAI_API_KEY ou GROQ_API_KEY) no arquivo .env do backend.",
                "sources": [],
                "suggestions": []
            }

        try:
            # Verificar se o LLM est√° dispon√≠vel antes de processar
            if not self.llm:
                return {
                    "message": "O servi√ßo de chat n√£o est√° dispon√≠vel. Por favor, configure uma chave de API (OPENAI_API_KEY ou GROQ_API_KEY) no arquivo .env do backend. Veja o arquivo CONFIGURAR_API.md para mais informa√ß√µes.",
                    "sources": [],
                    "suggestions": []
                }

            # Preparar mensagens para o modelo
            messages = []

            # Adicionar mensagem do sistema
            # Prompt otimizado para p√∫blico-alvo: Classes C, D, E - linguagem simples, educada e acess√≠vel
            system_prompt = """Voc√™ √© um assistente virtual educado e prestativo, especializado em legisla√ß√£o brasileira chamado Voz da Lei.
            
            SEU P√öBLICO: Cidad√£os brasileiros de todas as classes sociais, especialmente pessoas das classes C, D e E que n√£o t√™m 
            forma√ß√£o jur√≠dica. Muitos t√™m acesso limitado √† internet e baixa familiaridade com termos t√©cnicos.
            
            SUAS REGRAS FUNDAMENTAIS:
            1. SEJA SEMPRE EDUCADO E RESPEITOSO: Use "voc√™", "por favor", "obrigado". Trate o usu√°rio com educa√ß√£o e respeito, como um amigo que est√° ajudando.
            2. USE LINGUAGEM SIMPLES E POPULAR: Evite jarg√µes jur√≠dicos. Se precisar usar um termo t√©cnico, explique imediatamente de forma clara. Use palavras do dia a dia.
            3. SEJA DIRETO E OBJETIVO: Respostas curtas e objetivas (m√°ximo 3 par√°grafos quando poss√≠vel). Frases curtas e par√°grafos pequenos.
            4. USE EXEMPLOS PR√ÅTICOS E DO DIA A DIA: Sempre que poss√≠vel, d√™ exemplos que as pessoas entendam facilmente.
            5. SEJA EMP√ÅTICO E ACOLHEDOR: Entenda que o usu√°rio pode estar confuso, frustrado ou com medo. Seja paciente e acolhedor.
            6. SEMPRE USE FONTES CONFI√ÅVEIS: Baseie suas respostas APENAS em informa√ß√µes de fontes oficiais (LexML, Senado Federal, C√¢mara dos Deputados). Cite as fontes quando poss√≠vel.
            7. SEJA HONESTO: Se n√£o souber algo ou n√£o tiver informa√ß√£o confi√°vel, diga claramente: "N√£o tenho essa informa√ß√£o de forma confi√°vel no momento. Vou buscar para voc√™."
            8. FORMATO: Use par√°grafos curtos, listas quando ajudar, e evite textos longos. Use emojis com modera√ß√£o apenas para facilitar a leitura.
            
            INFORMA√á√ïES IMPORTANTES SOBRE AS FONTES DE DADOS:
            - As APIs oficiais (LexML, Senado Federal, C√¢mara dos Deputados) t√™m dados ATUALIZADOS at√© 2025.
            - Voc√™ tem acesso a informa√ß√µes legislativas RECENTES e ATUALIZADAS atrav√©s dessas APIs.
            - NUNCA diga que os dados v√£o "at√© outubro de 2023" ou qualquer data antiga - isso √© INCORRETO.
            - Se o usu√°rio perguntar sobre leis de 2024, 2025 ou qualquer ano recente, BUSQUE nas APIs antes de responder.
            - Se n√£o encontrar resultados na busca, diga que n√£o encontrou, mas N√ÉO invente limita√ß√µes de data.
            
            TOM DE VOZ:
            - Amig√°vel e acolhedor, como um amigo que est√° ajudando
            - Sempre positivo e encorajador
            - Nunca condescendente ou superior
            - Respeitoso e valorizando o conhecimento do usu√°rio
            
            EXEMPLO DE BOA RESPOSTA (EDUCADA E SIMPLES):
            "Ol√°! Fico feliz em ajudar voc√™! üòä
            
            Um projeto de lei √© como uma proposta que algu√©m faz para criar ou mudar uma lei. 
            √â como quando voc√™ sugere uma regra na sua casa, mas aqui √© para todo o Brasil.
            
            Exemplo pr√°tico: Se algu√©m quer que todos os √¥nibus tenham ar-condicionado, isso vira um projeto de lei.
            Depois, os deputados e senadores votam se concordam ou n√£o.
            
            Essa informa√ß√£o vem do site oficial do Senado Federal."
            
            EXEMPLO DE M√Å RESPOSTA (EVITAR):
            "Um projeto de lei √© uma proposi√ß√£o legislativa submetida ao Poder Legislativo para aprecia√ß√£o conforme os tr√¢mites regimentais estabelecidos..."
            
            REGRA CR√çTICA SOBRE CONTEXTO:
            - Quando voc√™ receber uma se√ß√£o "LEGISLA√á√ÉO ENCONTRADA NAS FONTES OFICIAIS" abaixo, voc√™ DEVE usar essas informa√ß√µes para responder.
            - Se o usu√°rio perguntar sobre uma lei que est√° listada nessa se√ß√£o, voc√™ DEVE explicar sobre ela usando as informa√ß√µes fornecidas.
            - N√ÉO diga que n√£o encontrou se a lei est√° listada na se√ß√£o de legisla√ß√£o encontrada.
            - Use o t√≠tulo, descri√ß√£o e data da lista para responder de forma clara e simples.
            
            Lembre-se: Voc√™ est√° democratizando o acesso √† informa√ß√£o. Seja claro, simples, educado e √∫til. Sempre baseie suas respostas em fontes oficiais e confi√°veis. As APIs t√™m dados atualizados at√© 2025 - use essas informa√ß√µes quando dispon√≠veis."""

            messages.append(SystemMessage(content=system_prompt))

            # Adicionar hist√≥rico de conversa
            if conversation_history:
                for msg in conversation_history:
                    role = msg.get("role", "user")
                    content = msg.get("content", "")
                    if role == "user":
                        messages.append(HumanMessage(content=content))
                    elif role == "assistant":
                        messages.append(AIMessage(content=content))

            # Buscar legisla√ß√£o relevante antes de responder
            legislation_context = ""
            try:
                # Buscar legisla√ß√£o relacionada (aumentar resultados para melhor matching)
                context = await unified_search.get_relevant_context(
                    query=message,
                    max_results=5
                )
                if context:
                    legislation_context = f"""\n\n=== LEGISLA√á√ÉO ENCONTRADA NAS FONTES OFICIAIS ===

{context}

=== INSTRU√á√ïES OBRIGAT√ìRIAS - LEIA COM ATEN√á√ÉO ===

REGRA ABSOLUTA: Se o usu√°rio perguntar sobre uma lei que est√° listada acima, voc√™ DEVE usar essas informa√ß√µes para responder. N√ÉO diga que n√£o encontrou se a lei est√° na lista acima.

EXEMPLO PR√ÅTICO:
- Usu√°rio pergunta: "Me explique sobre a Lei n¬∫ 2025"
- Voc√™ v√™ na lista acima: "1. Lei n¬∫ 2025, de 26 de Junho de 2025" com descri√ß√£o
- Voc√™ DEVE responder: "A Lei n¬∫ 2025, de 26 de junho de 2025, [usar a descri√ß√£o da lista]. Esta informa√ß√£o vem do LexML, que √© uma fonte oficial."

COMO RESPONDER QUANDO A LEI EST√Å NA LISTA:
1. Identifique qual lei da lista corresponde √† pergunta (procure pelo n√∫mero, t√≠tulo ou data)
2. Use o t√≠tulo, descri√ß√£o e data da lista acima para responder
3. Se a descri√ß√£o estiver dispon√≠vel, use-a para explicar sobre o que trata a lei de forma simples
4. Sempre mencione a fonte (LexML, Senado Federal, etc) no final
5. Se faltar detalhes, diga o que voc√™ sabe baseado na lista acima e mencione que mais informa√ß√µes podem ser obtidas na fonte oficial

N√ÉO FA√áA (ERRO GRAVE):
- N√ÉO diga "n√£o encontrei informa√ß√µes" se a lei est√° na lista acima
- N√ÉO diga "n√£o tenho acesso" se a informa√ß√£o est√° listada acima
- N√ÉO invente limita√ß√µes de data
- N√ÉO ignore a lista acima quando ela cont√©m a resposta

FONTES: Todas as informa√ß√µes acima v√™m de fontes oficiais (LexML, Senado Federal, C√¢mara dos Deputados) e est√£o atualizadas at√© 2025."""
                else:
                    # Se n√£o encontrou contexto, instruir o LLM a buscar nas APIs
                    legislation_context = """\n\nIMPORTANTE SOBRE BUSCA NAS APIs:

Voc√™ est√° conectado a APIs oficiais (LexML, Senado Federal, C√¢mara dos Deputados) que cont√™m dados atualizados at√© 2025.

QUANDO N√ÉO H√Å CONTEXTO LISTADO ACIMA:
- Isso significa que a busca autom√°tica n√£o encontrou resultados exatos
- MAS voc√™ ainda pode mencionar que existem leis relacionadas ao tema
- Voc√™ pode sugerir ao usu√°rio que consulte as fontes oficiais
- N√ÉO diga que n√£o h√° leis sobre o assunto - diga que n√£o encontrou informa√ß√µes espec√≠ficas no momento
- N√ÉO invente limita√ß√µes de data (como "dados at√© 2023")
- Seja honesto: "N√£o encontrei informa√ß√µes espec√≠ficas sobre [tema] nas fontes consultadas no momento, mas posso ajudar voc√™ a buscar nas fontes oficiais."

Lembre-se: As APIs t√™m dados atualizados e voc√™ deve sempre encorajar o usu√°rio a consultar as fontes oficiais quando n√£o tiver informa√ß√µes espec√≠ficas."""
            except Exception as e:
                logger.error(f"Erro ao buscar legisla√ß√£o: {str(e)}")
                # Continuar sem contexto se houver erro, mas logar o erro

            # Adicionar contexto de legisla√ß√£o se dispon√≠vel
            if legislation_context:
                messages.append(SystemMessage(content=legislation_context))

            # Adicionar mensagem atual
            messages.append(HumanMessage(content=message))

            # Obter resposta do modelo
            response = await self.llm.ainvoke(messages)
            response_text = response.content if hasattr(
                response, 'content') else str(response)

            # Buscar fontes para incluir na resposta
            sources = []
            try:
                search_results = await unified_search.search(message, limit=3)
                sources = [
                    {
                        "title": r.get("title", ""),
                        "source": r.get("source", ""),
                        "url": r.get("url", ""),
                        "date": r.get("date", "")
                    }
                    for r in search_results
                ]
            except Exception as e:
                logger.debug(f"Erro ao buscar fontes: {str(e)}")

            # Gerar sugest√µes baseadas na mensagem
            suggestions = self._generate_suggestions(message)

            return {
                "message": response_text,
                "sources": sources,
                "suggestions": suggestions
            }

        except Exception as e:
            error_msg = str(e)
            logger.error(f"Erro ao processar chat: {error_msg}")

            # Tratar erros de autentica√ß√£o especificamente
            if "401" in error_msg or "authentication_error" in error_msg or ("invalid" in error_msg.lower() and "api" in error_msg.lower()):
                return {
                    "message": "Erro de autentica√ß√£o: As chaves de API n√£o est√£o configuradas corretamente. Por favor, configure OPENAI_API_KEY ou GROQ_API_KEY no arquivo .env do backend.",
                    "sources": [],
                    "suggestions": []
                }

            # Tratar erro de modelo descontinuado
            if "model_decommissioned" in error_msg or "decommissioned" in error_msg.lower():
                return {
                    "message": "O modelo de IA foi atualizado. Por favor, reinicie o servidor backend para usar o novo modelo.",
                    "sources": [],
                    "suggestions": []
                }

            # Tratar outros erros de forma gen√©rica, mas com mais detalhes em modo DEBUG
            if settings.DEBUG:
                return {
                    "message": f"Erro ao processar mensagem: {error_msg[:200]}",
                    "sources": [],
                    "suggestions": []
                }

            return {
                "message": "Desculpe, ocorreu um erro ao processar sua mensagem. Por favor, tente novamente mais tarde.",
                "sources": [],
                "suggestions": []
            }

    def _generate_suggestions(self, message: str) -> List[str]:
        """Gerar sugest√µes de perguntas relacionadas"""
        # Sugest√µes padr√£o
        default_suggestions = [
            "O que √© um projeto de lei?",
            "Como funciona a tramita√ß√£o de uma PEC?",
            "Quais s√£o os projetos em vota√ß√£o hoje?",
            "Como posso acompanhar um projeto espec√≠fico?"
        ]

        # TODO: Implementar gera√ß√£o inteligente de sugest√µes baseada na mensagem
        return default_suggestions

    async def simplify_text(
        self,
        text: str,
        target_level: str = "simple"
    ) -> str:
        """
        Simplificar texto legislativo

        Args:
            text: Texto a ser simplificado
            target_level: N√≠vel de simplifica√ß√£o (simple, moderate, technical)

        Returns:
            Texto simplificado
        """
        if not self.llm:
            return "Servi√ßo de simplifica√ß√£o n√£o dispon√≠vel."

        try:
            prompt = f"""Simplifique o seguinte texto legislativo para um n√≠vel {target_level}.
            Mantenha o significado original, mas use linguagem mais acess√≠vel.
            
            Texto original:
            {text}
            
            Texto simplificado:"""

            response = await self.llm.ainvoke([HumanMessage(content=prompt)])
            return response.content if hasattr(response, 'content') else str(response)

        except Exception as e:
            logger.error(f"Erro ao simplificar texto: {str(e)}")
            return f"Erro ao simplificar texto: {str(e)}"


class SimplificationService:
    """Servi√ßo especializado para simplifica√ß√£o de textos legislativos"""

    def __init__(self):
        self.chat_service = ChatService()

    async def simplify_text(
        self,
        text: str,
        target_level: str = "simple"
    ) -> Dict[str, Any]:
        """
        Simplificar texto legislativo e retornar com metadados

        Args:
            text: Texto a ser simplificado
            target_level: N√≠vel de simplifica√ß√£o (simple, moderate, technical)

        Returns:
            Dict com 'simplified_text' e 'reading_time_minutes'
        """
        simplified = await self.chat_service.simplify_text(text, target_level)

        # Calcular tempo de leitura (assumindo ~200 palavras por minuto)
        word_count = len(simplified.split())
        reading_time = max(1, round(word_count / 200))

        return {
            "simplified_text": simplified,
            "reading_time_minutes": reading_time
        }


# Inst√¢ncias globais dos servi√ßos
chat_service = ChatService()
simplification_service = SimplificationService()
